{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-757a682d1119>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-757a682d1119>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    SPARK_CLASSPATH=/opt/cloudera/parcels/CDH/lib/hbase/bin\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, HiveContext\n",
    "import os\n",
    "\n",
    "# Modify the line below to change the number of executors and the amount of memory that they use \n",
    "# You can run Spark in local mode by changing 'yarn-client' to 'local', and setting the 'YARN_CONF_DIR' to ''\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master yarn-client --num-executors 1 --executor-memory 1g --packages com.databricks:spark-csv_2.10:1.5.0,com.databricks:spark-avro_2.11:3.0.1 pyspark-shell\"\n",
    "\n",
    "os.environ['YARN_CONF_DIR'] = os.path.join(os.environ[\"HDFS_CONFIGS\"], '3-null')\n",
    "cc.datasource_name = 'Cloudera CDH Pratik'\n",
    "# Each worker node in the cluster needs Python 2.7.\n",
    "# If this is not the default Python on the node, provide the Python path here\n",
    "# os.environ['PYSPARK_PYTHON'] = ''\n",
    "\n",
    "# Do not remove or modify the following line:\n",
    "# [[performPysparkInit(3)]]\n",
    "\n",
    "# This environment variable has the value 'workflow' when the notebook is being executed as part of an analytics workflow\n",
    "os.environ['NOTEBOOK_EXECUTION_ENVIRONMENT'] = 'notebook'\n",
    "# This will stop the SparkContext if there is one left over from a different notebook execution\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "APP_NAME = 'Hbase_Pyspark.ipynb-siteadmin'\n",
    "conf = SparkConf().setAppName(APP_NAME)\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "SPARK_CLASSPATH=/opt/cloudera/parcels/CDH/lib/hbase/bin\n",
    "pyspark --master yarn\n",
    "df = sqlContext.read.format('org.apache.hadoop.hbase.spark') \\\n",
    "    .option('hbase.table','customer') \\\n",
    "    .option('hbase.columns.mapping', \\\n",
    "            'ID INT :key, \\\n",
    "            firstname STRING info:firstname, \\\n",
    "            lastname STRING info:lastname') \\\n",
    "    .option('hbase.use.hbase.context', False) \\\n",
    "    .option('hbase.config.resources', 'file:///etc/hbase/conf.cloudera.hbase/hbase-site.xml') \\\n",
    "    .option('hbase-push.down.column.filter', False) \\\n",
    "    .load()\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datasets below were detected in your workspace when initializing Pyspark for data source 'Cloudera CDH Pratik'\n",
    "# To import these datasets into this notebook, uncomment one or more of the following lines:\n",
    "\n",
    "# b89dd6b5a3b74d4ba55cf7cd3c2ace1b = sc.textFile(\"/hbase/data/default/customer/1fb2e4f7673dd9c25fbd23018d5ca211/customer/b89dd6b5a3b74d4ba55cf7cd3c2ace1b\")\n",
    "# HorseshoeCrab_csv = sc.textFile(\"/HorseshoeCrab.csv\")\n",
    "# Iris_csv = sc.textFile(\"/Iris.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
